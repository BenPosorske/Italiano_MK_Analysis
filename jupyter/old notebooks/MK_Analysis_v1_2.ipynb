{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MK_Analysis\n",
    "This jupyter notebook is designed to analyze proplatelet production of Megakaryocytes from tiff time-lapses taken by the Incucyte Zoom (10X, 1392x1040px -- 1699.85 x 1549.40um).\n",
    "\n",
    "The Analysis workflow occurs in 3 steps:\n",
    "\n",
    "1 ilastikProcessing - Unpacks tiff stacks & generates probability masks from phase images through the ilastik project (.ilp) file.\n",
    "\n",
    "\n",
    "2 Quantification Pipeline - Primary pipeline for proplatelet production analysis. Important output files are listed as follows:\n",
    "    \n",
    "    a. 'results_Image.csv' -> raw results\n",
    "    \n",
    "    b. 'results_cell/pplt.properties' -> use in CPA to train classifiers\n",
    "    \n",
    "    c. 'labels' folder, containing 16-bt labels of proplatelet objects used for the Skeleton pipeline\n",
    "    \n",
    "    d. 'overlay' of phase images, labeling megs as red & pplts as green\n",
    "    \n",
    "    e. 'Raw.csv','Area.csv','Pplt_Pct.csv' -> Calculated & Formatted Results\n",
    "    \n",
    "3 Skeletonization Pipeline - Secondary pipeline for proplatelet structure analysis. Important output files are listed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakrith\\AppData\\Local\\conda\\conda\\envs\\bioimg\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import glob\n",
    "import h5py\n",
    "import matplotlib\n",
    "import numpy\n",
    "import os\n",
    "import os.path\n",
    "import pandas\n",
    "import re\n",
    "from shutil import copy2\n",
    "import skimage\n",
    "import skimage.exposure\n",
    "import skimage.io\n",
    "import subprocess\n",
    "# from tkinter.filedialog import askdirectory\n",
    "from tqdm._tqdm_notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ilastikProcessing\n",
    "To effectively use ilastik some formating must be done before and after ilastik processes the images. The input is assumed to be a time-series of images stored in a multi-page TIFF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpack (or separate) input images into single files.\n",
    "\n",
    "## Update input image variables\n",
    "Update the variable *image_directory* with the path to a folder that contains the input images. Update the *regex_image* variable to process only the images that match the regular expression. If the *regex_image* variable is equal to `(.*)\\.tif`, then any *.tif* in the folder will be processed.\n",
    "\n",
    "If a filename matches the *regex_single* regular expression, then it is assumed that this image has already been unpacked. An unpacked single image will have timepoint appended to the end of the file following the pattern `\\-\\d{4}\\.tif`\n",
    "\n",
    "*path_to_ilastik* is a string with the path to the ilastik software for [running headless](http://ilastik.org/documentation/basics/headless.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = r\"C:\\Users\\Prakrith\\Desktop\\test\"\n",
    "path_to_ilastik = r\"C:\\Program Files\\ilastik-1.3.0b4\\run-ilastik.bat\"\n",
    "path_to_project = r\"C:\\Users\\Prakrith\\Documents\\GitHub\\Test\\ilps\\180517_Zoom.ilp\"\n",
    "path_to_cellprofiler = r\"C:\\Program Files (x86)\\CellProfiler\\CellProfiler.exe\"\n",
    "path_to_cp_pipeline = r\"C:\\Users\\Prakrith\\Documents\\GitHub\\Test\\pipelines\\180512_MP.cppipe\"\n",
    "regex_image = \"(.*)\\.tif\" #stack\n",
    "regex_single = \".*\\-\\d{4}\\.tif\" #slice\n",
    "re_image = re.compile(regex_image)\n",
    "re_single = re.compile(regex_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(image_directory, \"single_images\"), exist_ok=True)\n",
    "imdir_single = os.path.join(image_directory,\"single_images\")\n",
    "os.makedirs(os.path.join(image_directory, \"ilastik\"), exist_ok=True)\n",
    "imdir_ilastik = os.path.join(image_directory,\"ilastik\")\n",
    "os.makedirs(os.path.join(image_directory, \"output\"), exist_ok=True)\n",
    "output_directory = os.path.join(image_directory,\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_directory = r\"C:\\Users\\Prakrith\\Desktop\\test\"\n",
    "# imdir_single = r\"C:\\Users\\Prakrith\\Desktop\\test\\single_images\"\n",
    "# imdir_ilastik = r\"C:\\Users\\Prakrith\\Desktop\\test\\ilastik\"\n",
    "# output_directory = r\"C:\\Users\\Prakrith\\Desktop\\test\\output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods to import image metadata\n",
    "* *is_my_file* will use the regular expression to filter image files to be processed.\n",
    "* *make_dict* parses a file to be processed and places metadata into a dictionary.\n",
    "\n",
    "Parse the files to be processed and then place the metadata into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_my_file(filename, re_image, re_single):\n",
    "    \n",
    "    mybool = False\n",
    "    \n",
    "    if (    re_image.match(filename) != None \n",
    "        and re_single.match(filename) == None\n",
    "       ):\n",
    "        \n",
    "        mybool = True\n",
    "        \n",
    "    return mybool\n",
    "\n",
    "\n",
    "def make_dict(filename, path, re_obj):\n",
    "    \n",
    "    my_dict = re_obj.match(filename).groupdict()\n",
    "    \n",
    "    my_dict[\"filename\"] = filename\n",
    "    \n",
    "    my_dict[\"path\"] = path\n",
    "    \n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files_dict = [make_dict(f, image_directory, re_image) for f in os.listdir(image_directory) if is_my_file(f, re_image, re_single)]\n",
    "image_df = pandas.DataFrame(image_files_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpack the multi-page TIFF images\n",
    "For every image, create a single image file for each timepoint. The input images are assumed to be RGB, which has 3 dimensions (length, width, color). The multipage TIFF of RGB images will have 4 dimensions (timepoints, length, width, color). \n",
    "\n",
    "*If the upstream workflow changes and the input image format is altered, then the conditional logic below will need to be updated, specifically the logic based on the shape of the input images.*\n",
    "\n",
    "### Are the images across experiments similar enough to treat equally\n",
    "One concern is that overfitting from training a classification model either through ilastik or CellProfiler analyst. The training set needs to be representative of the possibility space. This is accomplished by choosing a large enough image set that includes images of all states of interest including undifferentiated and fully differentiated megakaryocytes.\n",
    "\n",
    "We also want to eliminate noise from known sources of variablity that could potentially weaken the classifier. The primary sources of noise in the images will be non-uniform illumination and differences in exposure. Non-uniform illumination is difficult to correct, because the background is actually in the middle of the intensity range and the signal occupies both high and low intensities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filelist = glob.glob(\"D:\\Prakrith\\MK_Differentiation_Kyle\\images\\single_images\\*.tif\")\n",
    "\n",
    "#for f in filelist:\n",
    "    \n",
    "#    im = skimage.io.imread(f)\n",
    "    \n",
    "#    im2 = skimage.color.rgb2gray(im)\n",
    "        \n",
    "#    im2 = skimage.img_as_ubyte(im2)\n",
    "\n",
    "#    skimage.io.imsave(f, im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****DOWNSAMPLE\n",
    "\n",
    "# def df_stack_image(p):\n",
    "    \n",
    "#     im = skimage.io.imread(os.path.join(p[\"path\"], p[\"filename\"]))\n",
    "    \n",
    "#     if len(im.shape) < 4:\n",
    "        \n",
    "#         retest = re_image.match(p[\"filename\"])\n",
    "\n",
    "#         retest.group(1)\n",
    "\n",
    "#         fname = \"{0}-{1:04d}.tif\".format(retest.group(1), 0)\n",
    "        \n",
    "#         im2 = skimage.transform.rescale(im, 0.5)\n",
    "        \n",
    "#         im2 = skimage.color.rgb2gray(im2)\n",
    "        \n",
    "#         im2 = skimage.img_as_ubyte(im2)\n",
    "        \n",
    "#         skimage.io.imsave(os.path.join(p[\"path\"], fname), im2)\n",
    "        \n",
    "#     else:\n",
    "    \n",
    "#         number_of_timepoints = im.shape[0]\n",
    "\n",
    "#         for i in range(number_of_timepoints):\n",
    "\n",
    "#             retest = re_image.match(p[\"filename\"])\n",
    "\n",
    "#             retest.group(1)\n",
    "\n",
    "#             fname = \"{0}-{1:04d}.tif\".format(retest.group(1), i)\n",
    "            \n",
    "#             im2 = skimage.transform.rescale(im[i,:,:,:], 0.5)\n",
    "            \n",
    "#             im2 = skimage.color.rgb2gray(im2)\n",
    "        \n",
    "#             im2 = skimage.img_as_ubyte(im2)\n",
    "            \n",
    "#             skimage.io.imsave(os.path.join(p[\"path\"], \"single_images\", fname), im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_stack_image(p):\n",
    "    \n",
    "    im = skimage.io.imread(os.path.join(p[\"path\"], p[\"filename\"]))\n",
    "    \n",
    "    if len(im.shape) < 4:\n",
    "        \n",
    "        retest = re_image.match(p[\"filename\"])\n",
    "\n",
    "        retest.group(1)\n",
    "\n",
    "        fname = \"{0}-{1:04d}.tif\".format(retest.group(1), 0)\n",
    "        \n",
    "        im2 = skimage.color.rgb2gray(im)\n",
    "        \n",
    "        im2 = skimage.img_as_ubyte(im2)\n",
    "\n",
    "        skimage.io.imsave(os.path.join(p[\"path\"], fname), im2)\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        number_of_timepoints = im.shape[0]\n",
    "\n",
    "        for i in range(number_of_timepoints):\n",
    "\n",
    "            retest = re_image.match(p[\"filename\"])\n",
    "\n",
    "            retest.group(1)\n",
    "\n",
    "            fname = \"{0}-{1:04d}.tif\".format(retest.group(1), i)\n",
    "            \n",
    "            im2 = skimage.color.rgb2gray(im[i,:,:,:])\n",
    "        \n",
    "            im2 = skimage.img_as_ubyte(im2)\n",
    "\n",
    "            skimage.io.imsave(os.path.join(p[\"path\"], \"single_images\", fname), im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if image_df.empty is False:\n",
    "    \n",
    "    # Note that this can fail if the input images aren't in the expected format\n",
    "    # If you receive an error, double check the format of the input images, e.g. are they RGB?\n",
    "    tqdm_notebook.pandas(desc=\"unpack\")\n",
    "    _ = image_df.progress_apply(df_stack_image, axis=1)\n",
    "\n",
    "else:\n",
    "    \n",
    "    print(\"no images to unpack\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Run ilastik\n",
    "\n",
    "Using the single images created earlier, process the images using ilastik. First, create another dataframe with the single image metadata. Note, this has been written for running on Windows.\n",
    "\n",
    "## Process ilastik output for CellProfiler\n",
    "ilastik will output and HDF5 file that must be parsed for use as input to CellProfiler. This workflow assumes the default export settings are being used in ilastik. We have observed performance costs when changing the exporting settings to formats beyond the standard ilastik HDF5 file. For example, exporting TIFF images changes the shape of the exported data from yxc (the default) to cyx. This rearrangement will cause downstream errors, because the code as written expects the channel to be the third dimension.\n",
    "\n",
    "### ilastik stage-2 labels\n",
    "The project file *Mouse_MK.ilp* has the following labels that are stored in the same order within the HDF5 output.\n",
    "1. background\n",
    "1. border_white\n",
    "1. cell\n",
    "1. protrusion\n",
    "1. background_border\n",
    "1. not_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_my_file(filename, re_obj):\n",
    "    \n",
    "    mybool = False\n",
    "    \n",
    "    if re_obj.match(filename) != None:\n",
    "        \n",
    "        mybool = True\n",
    "        \n",
    "    return mybool\n",
    "\n",
    "\n",
    "def make_dict(filename, path, re_obj):\n",
    "    \n",
    "    my_dict = re_obj.match(filename).groupdict()\n",
    "    \n",
    "    my_dict[\"filename\"] = filename\n",
    "    \n",
    "    my_dict[\"path\"] = path\n",
    "    \n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files_dict = [make_dict(f, imdir_single, re_single) for f in os.listdir(imdir_single) if is_my_file(f, re_single)]\n",
    "image_df = pandas.DataFrame(image_files_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_ilastik(p):\n",
    "    \n",
    "    filename = os.path.join(p[\"path\"], p[\"filename\"])\n",
    "    \n",
    "    filename_noext = os.path.splitext(p[\"filename\"])[0]\n",
    "    \n",
    "    filename_h5 = \"{}_Probabilities Stage 2.h5\".format(filename_noext)\n",
    "    \n",
    "    # Run ilastik using subprocess\n",
    "    \n",
    "    process = subprocess.Popen([path_to_ilastik, \n",
    "                  \"--headless\",\n",
    "                  \"--export_source=probabilities stage 2\",\n",
    "                  \"--output_format=hdf5\",\n",
    "                  r\"--project={}\".format(path_to_project),\n",
    "                  filename\n",
    "                 ], stdout=subprocess.PIPE)\n",
    "    \n",
    "    out, err = process.communicate()\n",
    "    \n",
    "    # unpack the HDF5 file\n",
    "    \n",
    "    label_list = [\"background\", \"protrusion\", \"cell_boundary\", \"cell\"]\n",
    "    \n",
    "    path_h5 = os.path.join(p[\"path\"], filename_h5)\n",
    "    \n",
    "    with h5py.File(path_h5, \"r\") as ilastik_hdf5:\n",
    "    \n",
    "        ilastik_probabilities = ilastik_hdf5[\"exported_data\"].value\n",
    "    \n",
    "        for i in range(ilastik_probabilities.shape[2]):\n",
    "            im = skimage.img_as_uint(ilastik_probabilities[:, :, i])\n",
    "        \n",
    "            filename_slice = \"{}_{}_prbstg2_{}.png\".format(filename_noext, label_list[i], i)\n",
    "        \n",
    "            skimage.io.imsave(os.path.join(p[\"path\"], \"..\", \"ilastik\", filename_slice), im)\n",
    "    \n",
    "    os.remove(path_h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tqdm_notebook.pandas(desc=\"run ilastik\")\n",
    "_ = image_df.progress_apply(df_ilastik, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run CellProfiler\n",
    "\n",
    "## Make a filelist\n",
    "Add the paths to each file that will be processed by CellProfiler into a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Prakrith\\\\Desktop\\\\test\\\\fgb_rules_pplt.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CPA_Rules = r'C:\\Users\\Prakrith\\Desktop\\CPTemp_in\\fgb_rules_pplt.txt' #directory with location of CellProfiler Analyst Rules\n",
    "copy2(CPA_Rules, image_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_nicely(l):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(l, key = alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list = sorted_nicely(glob.glob(os.path.join(imdir_single,\"*.tif\")))\n",
    "ilastik_list = sorted_nicely(glob.glob(os.path.join(imdir_ilastik,\"*.png\")))\n",
    "big_list = single_list + ilastik_list\n",
    "with open(os.path.join(image_directory,\"filelist.txt\"), 'w') as f:\n",
    "    for item in big_list:\n",
    "        f.write(\"{}\\n\".format(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantification Pipeline\n",
    "Use subprocess to run CellProfiler on the images to be processed.\n",
    "\n",
    "Note, that a model that filters protrusions was trained in CellProfiler Analyst outside of this workflow. The model has to be in the input folder to be found by CellProfiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = subprocess.Popen([path_to_cellprofiler,\n",
    "                  \"--run-headless\",\n",
    "                  \"--pipeline={}\".format(path_to_cp_pipeline),\n",
    "                  \"--file-list={}\".format(os.path.join(image_directory,\"filelist.txt\")),\n",
    "                  \"--image-directory={}\".format(image_directory),\n",
    "                  \"--output-directory={}\".format(output_directory)\n",
    "                 ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n",
    "    \n",
    "out, err = process.communicate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantify Proplatelet Production\n",
    "From the csvs generated by CellProfiler, the file 'results_Image' is parsed, & proplatelet production is quantified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = range(df.shape[1]) #drops column headers\\\n",
    "# df = df.reindex(index=natsorted(df.index));\n",
    "\n",
    "# def sorted_nicely(l):\n",
    "#     convert = lambda text: int(text) if text.isdigit() else text\n",
    "#     alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "#     return sorted(l, key = alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = open(os.path.join(output_directory,r'results_Image.csv')); \n",
    "header = [\"URL_phase\",\"AreaOccupied_AreaOccupied_proplatelets\",\"Count_proplatelets\",\"Count_megs\",\"ImageNumber\"]; #\"AreaOccupied_AreaOccupied_megs\"\n",
    "df = pandas.read_csv(result, usecols = header, index_col = False);\n",
    "df = df.set_index(\"URL_phase\"); #won't allow setting URL_phase as index in read_csv\n",
    "df = df.reindex(index=sorted_nicely(df.index)); #reorder df alphanumerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    try:\n",
    "        return (((x[2])/(x[1]))*100) #(count_proplatelet/count_meg)*100\n",
    "    except ZeroDivisionError:\n",
    "        pass;\n",
    "    \n",
    "def g(x):\n",
    "    return ((x[0] * 2633747.59) / 1447680); #hard coded from IJ, [(area * total_area_um)/total_area_px]; AR = 1.22 um/px\n",
    "\n",
    "x = df.apply(f,axis=1);\n",
    "df['Pct'] = x;\n",
    "x = df.apply(g,axis=1);\n",
    "df['Area_um'] = x;\n",
    "df.to_csv(os.path.join(output_directory,'Raw.csv'));\n",
    "df.drop(df.columns[[0,1,2]], axis=1, inplace=True);\n",
    "df = df.set_index(\"ImageNumber\");\n",
    "df2 = pandas.DataFrame();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_list = sorted_nicely(glob.glob(os.path.join(image_directory,\"*.tif\")));\n",
    "t = int(len(single_list)); #total num images\n",
    "n = int((len(single_list) / len(stack_list))); # slices per stack\n",
    "\n",
    "for i in range(0,t,n):\n",
    "    slc = df.iloc[i:i+n]\n",
    "    slc = slc.reset_index(drop=True);\n",
    "    df2 = pandas.concat([df2,slc],axis=1,ignore_index=True); #iter df by stack length (n), and concat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(df,sl,n,name):\n",
    "    df.columns = sl;\n",
    "    df['Timepoint'] = list(range(1,n+1));\n",
    "    df = df.set_index(\"Timepoint\");\n",
    "    df.to_csv(os.path.join(output_directory,name)); #function adds headers to columns, fixes index, and creates final csv\n",
    "    \n",
    "a = df2.loc[:,1::2];\n",
    "h(a,stack_list,n,r'Area.csv')\n",
    "p = df2.loc[:,::2];\n",
    "h(p,stack_list,n,r'PPlt_Pct.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run CellProfiler - step #2\n",
    "\n",
    "## Make skeleton filelist\n",
    "Include the paths to each label file that will also be processed by CellProfiler into a text file.\n",
    "\n",
    "## Skeleton Pipeline\n",
    "Use subprocess to run CellProfiler on the images/labels to be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_sk_pipeline = r\"C:\\Users\\Prakrith\\Documents\\GitHub\\Test\\pipelines\\Kyle_Skel.cppipe\" #second pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(image_directory, \"skeleton\"), exist_ok=True)\n",
    "skeleton_directory = os.path.join(image_directory,\"skeleton\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdir_label = os.path.join(output_directory,\"labels\");\n",
    "label_list = sorted_nicely(glob.glob(os.path.join(imdir_label,\"*.tiff\")))\n",
    "skel_list = single_list + label_list\n",
    "with open(os.path.join(image_directory,\"filelist2.txt\"), 'w') as f:\n",
    "    for item in skel_list:\n",
    "        f.write(\"{}\\n\".format(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = subprocess.Popen([path_to_cellprofiler,\n",
    "                  \"--run-headless\",\n",
    "                  \"--pipeline={}\".format(path_to_sk_pipeline),\n",
    "                  \"--file-list={}\".format(os.path.join(image_directory,\"filelist2.txt\")),\n",
    "                  \"--image-directory={}\".format(image_directory),\n",
    "                  \"--output-directory={}\".format(skeleton_directory)\n",
    "                 ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n",
    "\n",
    "out, err = process.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices_csv = open(os.path.join(skeleton_directory,r'vertices.csv'));\n",
    "df = pd.read_csv(vertices_csv);\n",
    "df.columns = ['image_number', 'vertex_number','y','x','labels','kind'];#rename i,j to y,x\n",
    "cols = ['image_number', 'vertex_number', 'x','y','labels', 'kind'];\n",
    "df = df[cols];#swap y,x to x,y in vertices_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def node_find(vert,i):\n",
    "#     slc = vert[vert['image_number'] == i]; #slice by image\n",
    "#     slc = slc.drop(columns=['image_number']);\n",
    "#     nodes = slc.set_index('vertex_number').T.to_dict('list');\n",
    "#     return nodes; #takes all nodes from vert and converts to dict of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_csv = open(os.path.join(skeleton_directory,r'edges.csv'));\n",
    "e_df = pd.read_csv(edges_csv);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def node_finder(vert,i,location): #vert=vertex dataframe, i=image number, node location in (x,y)\n",
    "#     slc = vert[vert['image_number'] == i];\n",
    "#     slc2 = slc[(slc['x'] == location[0])]; #slice vertices in regards to x\n",
    "#     slc3 = slc2[(slc2['y'] == location[1])]; #reduce to 1 specific vertex via y\n",
    "#     node = slc3.iloc[0]['vertex_number']; #pull vertex_number\n",
    "#     kind = slc3.iloc[0]['kind']; #pull node,kind\n",
    "#     return node,kind;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_node(edge,node):\n",
    "    slc = edge[edge['image_number'] == i];\n",
    "    slc2 = slc[(slc['v1'] == v1[0])]; #slice vertex 1 \n",
    "    slc3 = slc2[(slc2['v2'] == v2[0])]; #reduce to single branch\n",
    "    length = slc3.iloc[0]['length']; #pull length between nodes\n",
    "    return length;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def branch_gen(v1,v2,length):\n",
    "    g = nx.Graph();\n",
    "    g.addnode(v1);\n",
    "    g.addnode(v2);\n",
    "    g.edge();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_find2(vert,i,l):\n",
    "    slc = vert[vert['image_number'] == i]\n",
    "    slc2 = slc[slc['labels'] == l];\n",
    "    slc2 = slc2.drop(columns=['image_number','labels']);\n",
    "    nodes = slc2.set_index('vertex_number').T.to_dict('list');\n",
    "    return nodes; #takes nodes from specific proplatelet struct within specific img, return as dict of list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_find(edge,i):\n",
    "    slc = edge[edge['image_number'] == i];\n",
    "    slc = slc.drop(columns=['image_number','total_intensity']);\n",
    "#     edges = slc.set_index('vertex_number').T.to_dict('list');\n",
    "    return edges;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = DiGraph()\n",
    "# nodes = csv.DictReader(open(nodeFile, 'rU'), ['index', 'label', 'type'])\n",
    "# for row in nodes:\n",
    "#     G.add_node(row['index'], {'index':row['index'], 'label':row['label'], 'type':row['type']})\n",
    "# edges = csv.DictReader(open(edgeFile, 'rU'), ['v1', 'v2', 'weight'])\n",
    "# for row in edges:\n",
    "#     G.add_edge(row['v1'], row['v2'], row[weight'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
